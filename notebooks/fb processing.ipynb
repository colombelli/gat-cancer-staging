{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c20dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b7c8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/home/colombelli/Documents/datasets/pankidney firebrowse/\"\n",
    "\n",
    "def load_data(base):\n",
    "    gene = pd.read_csv(base + 'gene.txt', sep='\\t', index_col=0)\n",
    "    mirna = pd.read_csv(base + 'mirna.txt', sep='\\t', index_col=0)\n",
    "    meth = pd.read_csv(base + 'meth.txt', sep='\\t', index_col=0)\n",
    "    clin = pd.read_csv(base + 'clin.txt', sep='\\t', index_col=0)\n",
    "    return gene.T, mirna.T, meth.T.iloc[:, 1:], clin.T.iloc[:, [6]]\n",
    "\n",
    "def log2(gene, mirna):\n",
    "    return np.log2(gene+1), np.log2(mirna+1)\n",
    "\n",
    "def process_nan_values(df):\n",
    "    processed_df = df\n",
    "    max_nan_values = len(df) * 0.05\n",
    "    for col in df.columns:\n",
    "        nan_count = df[col].isnull().sum()\n",
    "        if nan_count > max_nan_values:\n",
    "            processed_df = processed_df.drop(col, axis=1) \n",
    "            \n",
    "    print(\"Columns before nan processing: \", len(df.columns))\n",
    "    print(\"Columns after nan processing: \", len(processed_df.columns))\n",
    "    return processed_df.fillna(0)\n",
    "\n",
    "\n",
    "# Currently the meadian of the vial values are used as the sample value\n",
    "def process_vial(df, idx):\n",
    "    new_idx=[]\n",
    "    for i in idx:\n",
    "        if len(i.split('-')[-1]) > 2:\n",
    "            new_idx.append(i[:-1])\n",
    "    \n",
    "    df['index'] = new_idx # Possibly, there will be repeated indexes => mean the value\n",
    "    return df.groupby(['index']).mean()\n",
    "    \n",
    "\n",
    "def process_indexes(df):\n",
    "    # Get only the following infos from barcode: \n",
    "    # Project-TSS-Participant-Sample_Vial (Vial if present, otherwise only sample)\n",
    "    idx = ['-'.join(i.split('-')[:4]) for i in df.index]\n",
    "\n",
    "    # Check if idx has only unique elements\n",
    "    if(len(set(idx)) != len(idx)):\n",
    "        raise(Exception(\"Indexes processing resulted in colliding indexes! Aborting...\"))\n",
    "        \n",
    "    # Check if vial info is present:\n",
    "    for i in idx:\n",
    "        if len(i.split('-')[-1]) > 2: # It is present\n",
    "            return process_vial(df, idx)\n",
    "    \n",
    "    df.index = idx\n",
    "    return df\n",
    "    \n",
    "    \n",
    "\n",
    "def get_classes(df, clin):\n",
    "    \n",
    "    normal = []\n",
    "    stage1 = []\n",
    "    stage2 = []\n",
    "    stage3 = []\n",
    "    stage4 = []\n",
    "    \n",
    "    for barcode in df.index:\n",
    "        splt = barcode.split('-')\n",
    "        patient_id = '-'.join(splt[:-1]).lower()\n",
    "        sample_type = splt[-1]\n",
    "        \n",
    "        if int(sample_type) <= 9: # Tumoral sample\n",
    "            stage = clin.loc[patient_id,'pathologic_stage']\n",
    "            if stage == 'stage i':\n",
    "                stage1.append(barcode)\n",
    "            elif stage == 'stage ii':\n",
    "                stage2.append(barcode)\n",
    "            elif stage == 'stage iii':\n",
    "                stage3.append(barcode)\n",
    "            elif stage == 'stage iv':\n",
    "                stage4.append(barcode)\n",
    "            else:\n",
    "                print(\"Unexpected stage (\"+str(stage)+\") for patient: \", patient_id, \"\\nIgnoring...\")\n",
    "            \n",
    "            \n",
    "        elif int(sample_type) <= 19:  # Normal sample\n",
    "            normal.append(barcode)\n",
    "            \n",
    "        # else: control sample -> ignore\n",
    "        \n",
    "        \n",
    "    return normal, stage1, stage2, stage3, stage4\n",
    "\n",
    "\n",
    "def save_splitted_df(base_path, df, normal, stage1, stage2, stage3, stage4):\n",
    "    df[df.index.isin(normal)].to_csv(base_path+\"normal.csv\")\n",
    "    df[df.index.isin(stage1)].to_csv(base_path+\"stage1.csv\")\n",
    "    df[df.index.isin(stage2)].to_csv(base_path+\"stage2.csv\")        \n",
    "    df[df.index.isin(stage3)].to_csv(base_path+\"stage3.csv\")        \n",
    "    df[df.index.isin(stage4)].to_csv(base_path+\"stage4.csv\")\n",
    "    return\n",
    "\n",
    "\n",
    "def save_processed_dfs(base_path, gene, mirna, meth):\n",
    "    gene.to_csv(base_path+\"gene_proc.csv\")\n",
    "    if isinstance(mirna, pd.DataFrame):\n",
    "        mirna.to_csv(base_path+\"mirna_proc.csv\")\n",
    "    if isinstance(meth, pd.DataFrame):\n",
    "        meth.to_csv(base_path+\"meth_proc.csv\")\n",
    "    return\n",
    "    \n",
    "\n",
    "def save_classes(base_path, df, stages):\n",
    "    flatten_idx = [item for sublist in stages for item in sublist]\n",
    "    normal = ['normal']*len(stages[0])\n",
    "    stage1 = ['stage1']*len(stages[1])\n",
    "    stage2 = ['stage2']*len(stages[2])\n",
    "    stage3 = ['stage3']*len(stages[3])\n",
    "    stage4 = ['stage4']*len(stages[4])\n",
    "    \n",
    "    class_col = normal+stage1+stage2+stage3+stage4\n",
    "    \n",
    "    classes = pd.DataFrame({'id':flatten_idx, 'class':class_col})\n",
    "    classes = classes.loc[classes['id'].isin(df.index)]\n",
    "    \n",
    "    classes.to_csv(base_path+\"stellargraph/classes.csv\", index=False)\n",
    "    return\n",
    "    \n",
    "    \n",
    "\n",
    "# dataframes: [gene, mirna, meth]\n",
    "# stages: [normal, stage1, stage2, stage3, stage4]\n",
    "# only_common: if the dataframes to be saved are supposed to have only common samples\n",
    "def save_dfs(base_path, dataframes, stages, only_common=True):\n",
    "        \n",
    "    normal, stage1, stage2, stage3, stage4 = stages\n",
    "    \n",
    "    # Eliminate samples without label\n",
    "    all_possible_indexes = [item for sublist in stages for item in sublist]\n",
    "    \n",
    "    no_integration=False\n",
    "    if len(dataframes) == 1:\n",
    "        print(\"No omics integration will be considered!\\n\")\n",
    "        no_integration=True\n",
    "    \n",
    "    if no_integration:\n",
    "        gene = dataframes[0]\n",
    "        gene = gene[gene.index.isin(all_possible_indexes)]\n",
    "        mirna=None\n",
    "        meth=None\n",
    "        \n",
    "    else:\n",
    "        gene, mirna, meth = dataframes\n",
    "        gene = gene[gene.index.isin(all_possible_indexes)]\n",
    "        mirna = mirna[mirna.index.isin(all_possible_indexes)]\n",
    "        meth = meth[meth.index.isin(all_possible_indexes)]\n",
    "    \n",
    "    if only_common:\n",
    "        if no_integration:\n",
    "            common_samples = list(gene.index)\n",
    "            gene = gene.loc[common_samples, :]\n",
    "        else:\n",
    "            common_samples = list(set(gene.index)&set(mirna.index)&set(meth.index))\n",
    "            gene = gene.loc[common_samples, :]\n",
    "            mirna = mirna.loc[common_samples, :]\n",
    "            meth = meth.loc[common_samples, :]\n",
    "\n",
    "            \n",
    "        cs = set(common_samples)\n",
    "        \n",
    "        print(\"Number of common samples (inter-omics) by class:\")\n",
    "        print(\"normal: \", len(cs&set(normal)))\n",
    "        print(\"stage1: \", len(cs&set(stage1)))\n",
    "        print(\"stage2: \", len(cs&set(stage2)))\n",
    "        print(\"stage3: \", len(cs&set(stage3)))\n",
    "        print(\"stage4: \", len(cs&set(stage4)))\n",
    "        print(\"\\nTotal samples: \", len(cs))\n",
    "    \n",
    "    save_classes(base_path, gene, stages)\n",
    "    save_splitted_df(base_path+\"split_class/\", gene, normal, stage1, stage2, stage3, stage4)\n",
    "    save_processed_dfs(base_path, gene, mirna, meth)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37edc039",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colombelli/.pyenv/versions/3.6.13/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "gene, mirna, meth, clin = load_data(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91cebd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene expression\n",
      "Columns before nan processing:  20531\n",
      "Columns after nan processing:  20531\n",
      "\n",
      "miRNA expression\n",
      "Columns before nan processing:  2588\n",
      "Columns after nan processing:  341\n",
      "\n",
      "Methylation\n",
      "Columns before nan processing:  20116\n",
      "Columns after nan processing:  20116\n",
      "\n",
      "Unexpected stage (nan) for patient:  tcga-bp-4798 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-mm-a563 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9jv \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9jw \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9jy \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9jz \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9k0 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9k2 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9k3 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9k4 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9k6 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9k8 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9k9 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9ka \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9kc \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9ke \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9kf \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-5p-a9kh \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-a4-7286 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-a4-7288 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-a4-7732 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-al-3467 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-al-3472 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-b9-4114 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-b9-4116 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-b9-4117 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-b9-4617 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-b9-5156 \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-he-a5nj \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-he-a5nk \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-ia-a83s \n",
      "Ignoring...\n",
      "Unexpected stage (nan) for patient:  tcga-ia-a83t \n",
      "Ignoring...\n"
     ]
    }
   ],
   "source": [
    "gene, mirna = log2(gene, mirna)\n",
    "\n",
    "print(\"Gene expression\")\n",
    "gene = process_indexes(process_nan_values(gene))\n",
    "print(\"\\nmiRNA expression\")\n",
    "mirna = process_indexes(process_nan_values(mirna))\n",
    "print(\"\\nMethylation\")\n",
    "meth = process_indexes(process_nan_values(meth))\n",
    "\n",
    "print()\n",
    "normal, stage1, stage2, stage3, stage4 = get_classes(gene, clin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96ec7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal samples:  129\n",
      "Stage 1 samples:  461\n",
      "Stage 2 samples:  104\n",
      "Stage 3 samples:  189\n",
      "Stage 4 samples:  105\n",
      "\n",
      "Total samples:  988\n"
     ]
    }
   ],
   "source": [
    "print(\"Normal samples: \", len(normal))\n",
    "print(\"Stage 1 samples: \", len(stage1))\n",
    "print(\"Stage 2 samples: \", len(stage2))\n",
    "print(\"Stage 3 samples: \", len(stage3))\n",
    "print(\"Stage 4 samples: \", len(stage4))\n",
    "\n",
    "print(\"\\nTotal samples: \", len(normal)+len(stage1)+len(stage2)+len(stage3)+len(stage4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a87d4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common samples (inter-omics) by class:\n",
      "normal:  47\n",
      "stage1:  284\n",
      "stage2:  65\n",
      "stage3:  98\n",
      "stage4:  53\n",
      "\n",
      "Total samples:  547\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/home/colombelli/Documents/datasets/pankidney firebrowse/\"\n",
    "dataframes=[gene,mirna,meth]  #for no integration = [gene]\n",
    "stages=[normal, stage1, stage2, stage3, stage4]\n",
    "save_dfs(base_path, dataframes, stages, only_common=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba4031f",
   "metadata": {},
   "source": [
    "# Second processing part\n",
    "\n",
    "### Features definition by IQR selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5538277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k_highest_iqr(k, df):\n",
    "    iqrs=[]\n",
    "    for col in df.columns:\n",
    "        iqrs.append(iqr(df[col]))\n",
    "            \n",
    "    selected_idx = (-np.array(iqrs)).argsort()[:k]\n",
    "    return df.iloc[:, selected_idx]\n",
    "\n",
    "\n",
    "# k_iqrs: [gene_expr, mirna_expr, meth_expr]\n",
    "def build_iqr_features_df(base_path, k_iqrs, integration=True, drop_samples_with_missing_features=True):\n",
    "    gene = pd.read_csv(base_path+\"gene_proc.csv\", index_col=0)\n",
    "    \n",
    "    if integration:\n",
    "        mirna = pd.read_csv(base_path+\"mirna_proc.csv\", index_col=0)\n",
    "        meth = pd.read_csv(base_path+\"meth_proc.csv\", index_col=0) \n",
    "        dfs = [gene,mirna,meth]\n",
    "        \n",
    "    else:\n",
    "        dfs = [gene]\n",
    "        \n",
    "    sel_dfs = []\n",
    "    for i, df in enumerate(dfs):\n",
    "        sel_dfs.append(select_k_highest_iqr(k_iqrs[i], df))\n",
    "    \n",
    "    sel_dfs[0].T.to_csv(base_path+\"gene_iqr.csv\")\n",
    "    \n",
    "    features_df = pd.concat(sel_dfs, axis=1)\n",
    "    if drop_samples_with_missing_features:\n",
    "        features_df = features_df.dropna(axis=0)\n",
    "        \n",
    "    features_df.to_csv(base_path+\"stellargraph/features.csv\")\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c018c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_k_iqr = 500\n",
    "mirna_k_iqr = 100\n",
    "meth_k_iqr = 100\n",
    "\n",
    "base_path=\"/home/colombelli/Documents/datasets/pankidney firebrowse/\"\n",
    "integration=True #for no integration = False\n",
    "drop_missing_features=True\n",
    "fdf = build_iqr_features_df(base_path, [gene_k_iqr, mirna_k_iqr, meth_k_iqr], integration, drop_missing_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d768d",
   "metadata": {},
   "source": [
    "# At this point the coexp_net_build.r must be executed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cdccbc",
   "metadata": {},
   "source": [
    "# Third processing part\n",
    "\n",
    "### Transform correlation data into loadable stellargraph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c63e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_to_edges(base_path, networks):\n",
    "    for net in networks:\n",
    "        path = base_path+net+\"/\"\n",
    "        df = pd.read_csv(path+\"corr.txt\", sep=\" \", header=None)\n",
    "        df.columns = [\"source\", \"target\", \"weight\"]\n",
    "        \n",
    "        new_ids = [i.replace('.', '-') for i in df['source'].values]\n",
    "        df['source'] = new_ids\n",
    "        \n",
    "        new_ids = [i.replace('.', '-') for i in df['target'].values]\n",
    "        df['target'] = new_ids\n",
    "        \n",
    "        df.to_csv(path+\"edges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9b98d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/colombelli/Documents/datasets/pankidney firebrowse/stellargraph/\"\n",
    "networks = [\"N1\", \"N2\", \"N3\", \"N4\", \"N5\"]\n",
    "corr_to_edges(base_path, networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805becc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
