{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc71ba95-9d32-4cd1-a766-bb65c7555fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import spectral_clustering\n",
    "from sklearn.metrics import v_measure_score\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d9b6c7d6-1ae8-40a0-be3a-71357e44c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_dataframe(df):\n",
    "    col_1 = []\n",
    "    col_2 = []\n",
    "    col_r = []\n",
    "    col_p = []\n",
    "    \n",
    "    for idx1, row1 in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        for idx2, row2 in df.loc[idx1:, :].iterrows():\n",
    "            r, p = stats.pearsonr(row1.values, row2.values)\n",
    "            col_1.append(idx1)\n",
    "            col_2.append(idx2)\n",
    "            col_r.append(r)\n",
    "            col_p.append(p)\n",
    "            \n",
    "    corr_df = pd.DataFrame.from_dict({\n",
    "        \"sample1\": col_1,\n",
    "        \"sample2\": col_2,\n",
    "        \"r\": col_r,\n",
    "        \"p\": col_p\n",
    "    })\n",
    "    return corr_df\n",
    "\n",
    "\n",
    "def merge_correlation_dataframes(dfs):\n",
    "    \n",
    "    greatest_r = np.argmax(np.array([df.r for df in dfs]), axis=0)\n",
    "    to_concat = [df.loc[greatest_r == i] for i, df in enumerate(dfs)]\n",
    "    return pd.concat(to_concat).sort_index()\n",
    "\n",
    "\n",
    "def build_edge_list(df, r_filter, p_filter):\n",
    "    edges_df = df.loc[(df.r >= r_filter) & (df['p'] <= p_filter)]\n",
    "    return edges_df.rename(columns={'sample1':'source', 'sample2':'target'})\n",
    "\n",
    "def filter_relevant_connections(df, threshold):\n",
    "    return df.loc[(df.weight >= threshold)]\n",
    "\n",
    "\n",
    "def generate_csvs(edges_df, class_df, max_each_feature=100, multi_omics=True):\n",
    "    \n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    edges_df.to_csv(save_dir+\"edges.csv\", index=False)\n",
    "    class_df.to_csv(save_dir+\"classes.csv\", index=True)\n",
    "    \n",
    "    gene = pd.read_csv(f\"{base}{cancer}_mRNA.csv\", index_col=0).iloc[:max_each_feature, :]\n",
    "    if multi_omics:\n",
    "        mirna = pd.read_csv(f\"{base}{cancer}_miRNA.csv\", index_col=0).iloc[:max_each_feature, :]\n",
    "        meth = pd.read_csv(f\"{base}{cancer}_Methy.csv\", index_col=0).iloc[:max_each_feature, :] \n",
    "        #cnv = pd.read_csv(f\"{base}{cancer}_CNV.csv\", index_col=0).iloc[:max_each_feature, :]\n",
    "        #features_df = pd.concat([gene,mirna,meth,cnv]).T\n",
    "        features_df = pd.concat([gene,mirna,meth]).T\n",
    "    else:\n",
    "        features_df = gene.T\n",
    "    \n",
    "    features_df.loc[class_df.index, :].to_csv(save_dir+\"features.csv\", index=True)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def get_correlation_vector(A, B, th):\n",
    "    # Get number of rows in either A or B\n",
    "    N = B.shape[0]\n",
    "\n",
    "    # Store columnw-wise in A and B, as they would be used at few places\n",
    "    sA = A.sum(0)\n",
    "    sB = B.sum(0)\n",
    "\n",
    "    # Basically there are four parts in the formula. We would compute them one-by-one\n",
    "    p1 = N*np.einsum('ij,ik->kj',A,B)\n",
    "    p2 = sA*sB[:,None]\n",
    "    p3 = N*((B**2).sum(0)) - (sB**2)\n",
    "    p4 = N*((A**2).sum(0)) - (sA**2)\n",
    "\n",
    "    # Finally compute Pearson Correlation Coefficient as 2D array \n",
    "    pcorr = ((p1 - p2)/np.sqrt(p4*p3[:,None]))\n",
    "    corr_vec = pcorr[np.tril_indices(n=A.shape[1],m=B.shape[1], k=-1)]\n",
    "    corr_vec[np.absolute(corr_vec) > th] = 0\n",
    "    return corr_vec\n",
    "\n",
    "\n",
    "def get_classification_vector(sample, s1, s2, s3, s4, th):\n",
    "    #print(s1)\n",
    "    #print(sample)\n",
    "    ps1 = np.vstack([s1, sample])\n",
    "    ps1 = get_correlation_vector(ps1, ps1, th)\n",
    "    \n",
    "    ps2 = np.vstack([s2, sample])\n",
    "    ps2 = get_correlation_vector(ps2, ps2, th)\n",
    "    \n",
    "    ps3 = np.vstack([s3, sample])\n",
    "    ps3 = get_correlation_vector(ps3, ps3, th)\n",
    "    \n",
    "    ps4 = np.vstack([s4, sample])\n",
    "    ps4 = get_correlation_vector(ps4, ps4, th)\n",
    "    return np.concatenate([ps1,ps2,ps3,ps4])\n",
    "    \n",
    "    \n",
    "def build_dataset(features, classes, th, seed):\n",
    "    y_train, y_base_test = train_test_split(classes, stratify=classes, test_size=0.6, random_state=seed, shuffle=True)\n",
    "    y_base, y_test = train_test_split(y_base_test, stratify=y_base_test, test_size=0.5, random_state=seed, shuffle=True)\n",
    "    \n",
    "    s1 = features.loc[y_base.loc[y_base['class'] == 'stage1'].index, :]\n",
    "    s2 = features.loc[y_base.loc[y_base['class'] == 'stage2'].index, :]\n",
    "    s3 = features.loc[y_base.loc[y_base['class'] == 'stage3'].index, :]\n",
    "    s4 = features.loc[y_base.loc[y_base['class'] == 'stage4'].index, :]\n",
    "    \n",
    "    x_train = []\n",
    "    x_train_features = features.loc[y_train.index, :]\n",
    "    for _, row in tqdm(x_train_features.iterrows(), total=x_train_features.shape[0]):\n",
    "        x_train.append(get_classification_vector(row.values, s1, s2, s3, s4, th))\n",
    "    \n",
    "    x_test = []\n",
    "    x_test_features = features.loc[y_test.index, :]\n",
    "    for _, row in tqdm(x_test_features.iterrows(), total=x_test_features.shape[0]):\n",
    "        x_test.append(get_classification_vector(row.values, s1, s2, s3, s4, th))\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a2605ca-19e8-4227-aacb-30b9fb2dfade",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = \"KIRC\"\n",
    "threshold_r = 0.7\n",
    "threshold_p = 0.05\n",
    "\n",
    "base = f\"C:/Users/colombelli/Desktop/TCC/experiments_extra_40/{cancer}/\"\n",
    "\n",
    "df = pd.read_csv(f\"{base}{cancer}_mRNA.csv\", index_col=0).T\n",
    "df_classes = build_class_df(list(df.index), agglutinate_stages=False).dropna()\n",
    "df = df.loc[class_df.index, :]\n",
    "\n",
    "#corr_df = get_correlation_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "be48187b-3e4b-4591-9f7c-222cba11fd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 125/125 [01:17<00:00,  1.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 94/94 [01:02<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = build_dataset(df, df_classes, 0.7, 2643643)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b579ed1f-0403-4349-9855-7fe43cb8dd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46808510638297873"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(np.array(x_train), y_train['class'].values)\n",
    "clf.score(np.array(x_test), y_test['class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ab657-10dd-4300-a0ad-b09b9e9248bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
